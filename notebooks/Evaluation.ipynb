{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T21:37:46.397601Z",
     "start_time": "2024-05-13T21:37:46.395195Z"
    }
   },
   "source": [
    "import pprint\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "from utils import preprocess_text, labelnum"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:37:46.729643Z",
     "start_time": "2024-05-13T21:37:46.727486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "SENTIMENT_MODEL_PATH = './models/sentiment/'"
   ],
   "id": "f8f3ba6dde0388a",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:37:47.122958Z",
     "start_time": "2024-05-13T21:37:47.120377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "transformers.set_seed(seed)"
   ],
   "id": "1256ef2cb002e996",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# seBERT",
   "id": "1bfb4a4c0cd94942"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:37:48.271431Z",
     "start_time": "2024-05-13T21:37:47.941189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForSequenceClassification.from_pretrained(SENTIMENT_MODEL_PATH)\n",
    "tokenizer = BertTokenizer.from_pretrained(SENTIMENT_MODEL_PATH)"
   ],
   "id": "c75be1719a0d917e",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:37:48.602762Z",
     "start_time": "2024-05-13T21:37:48.587977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data/processed/evaluation.csv')\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "df['label'] = df['label'].map(labelnum)\n",
    "\n",
    "df['label'].value_counts()"
   ],
   "id": "bf5399f34be0ac36",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:38:10.398442Z",
     "start_time": "2024-05-13T21:37:49.250266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = [str(i) for i in df['text'].tolist()]\n",
    "y_test = [int(i) for i in df['label'].tolist()]\n",
    "\n",
    "data_len = len(df)\n",
    "y_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _, X_row in enumerate(X):\n",
    "        inputs = tokenizer(X_row, padding=True, truncation=True, max_length=128, return_tensors='pt').to('cuda')\n",
    "        outputs = model.to('cuda')(**inputs)\n",
    "        probs = outputs[0].softmax(1).cpu().detach().numpy()\n",
    "        y_probs.append(probs)\n",
    "            \n",
    "y_pred = []\n",
    "for y_prob in y_probs:\n",
    "    y_pred.append(y_prob.argmax())"
   ],
   "id": "d08f630db86dbd6b",
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:38:11.857959Z",
     "start_time": "2024-05-13T21:38:11.853679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metrics(y_test, y_pred, identifier):\n",
    "    return [{'model': identifier,\n",
    "            'mcc': matthews_corrcoef(y_true=y_test, y_pred=y_pred),\n",
    "            'micro_f1': f1_score(y_true=y_test, y_pred=y_pred, average='micro'),\n",
    "            'micro_precision': precision_score(y_true=y_test, y_pred=y_pred, average='micro'),\n",
    "            'micro_recall': recall_score(y_true=y_test, y_pred=y_pred, average='micro'),\n",
    "            'macro_f1': f1_score(y_true=y_test, y_pred=y_pred, average='macro'),\n",
    "            'macro_precision': precision_score(y_true=y_test, y_pred=y_pred, average='macro'),\n",
    "            'macro_recall': recall_score(y_true=y_test, y_pred=y_pred, average='macro'),\n",
    "            'precision_negative': precision_score(y_true=y_test, y_pred=y_pred, average=None, labels=[0])[0],\n",
    "            'precision_neutral': precision_score(y_true=y_test, y_pred=y_pred, average=None, labels=[1])[0],\n",
    "            'precision_positive': precision_score(y_true=y_test, y_pred=y_pred, average=None, labels=[2])[0],\n",
    "            'recall_negative': recall_score(y_true=y_test, y_pred=y_pred, average=None, labels=[0])[0],\n",
    "            'recall_neutral': recall_score(y_true=y_test, y_pred=y_pred, average=None, labels=[1])[0],\n",
    "            'recall_positive': recall_score(y_true=y_test, y_pred=y_pred, average=None, labels=[2])[0],\n",
    "            'f1_negative': f1_score(y_true=y_test, y_pred=y_pred, average=None, labels=[0])[0],\n",
    "            'f1_neutral': f1_score(y_true=y_test, y_pred=y_pred, average=None, labels=[1])[0],\n",
    "            'f1_positive': f1_score(y_true=y_test, y_pred=y_pred, average=None, labels=[2])[0]}]"
   ],
   "id": "ec569c624a1cf81d",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:38:12.671434Z",
     "start_time": "2024-05-13T21:38:12.637367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = get_metrics(y_test, y_pred, 'seBERT')\n",
    "\n",
    "pprint.pprint(results)\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv('./models/evaluation/evaluated.csv', index=False)"
   ],
   "id": "c0f88beb207cc297",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SentiStrength-SE_v1.5",
   "id": "564f66eed393487d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:38:15.037063Z",
     "start_time": "2024-05-13T21:38:15.023574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ssse = pd.read_csv('./data/processed/evaluation_ssse_preds.csv')\n",
    "ssse['text'] = ssse['text'].apply(preprocess_text)\n",
    "ssse['label'] = ssse['label'].map(labelnum)\n",
    "\n",
    "ssse_preds = [int(i) for i in ssse['label'].tolist()]"
   ],
   "id": "cf21fe4f2ad8237a",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:38:16.262414Z",
     "start_time": "2024-05-13T21:38:16.212765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ssse_results = get_metrics(y_test, ssse_preds, 'SentiStrength-SE_v1.5')\n",
    "\n",
    "pprint.pprint(ssse_results)\n",
    "\n",
    "ssse_results_df = pd.DataFrame(ssse_results)\n",
    "ssse_results_df.to_csv('./models/evaluation/evaluated.csv', index=False, mode='a', header=False)"
   ],
   "id": "14904f17f6cae3f",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "e25ac73d65ee6fdb",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot",
   "id": "32c9c9ecd39ec3c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:46:58.406892Z",
     "start_time": "2024-05-13T21:46:58.123517Z"
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt",
   "id": "f44de8e7d3c224c3",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T21:47:39.172593Z",
     "start_time": "2024-05-13T21:47:38.889888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluated = pd.read_csv('./models/evaluation/evaluated.csv')\n",
    "\n",
    "# plot precision, recall, f1 score for each class for both of the models\n",
    "fig, ax = plt.subplots(1, 3, figsize=(40, 10))\n",
    "\n",
    "evaluated[['precision_negative', 'precision_neutral', 'precision_positive']].plot(kind='bar', ax=ax[0])\n",
    "ax[0].set_title('Precision')\n",
    "ax[0].set_xticklabels(['seBERT', 'SentiStrength-SE_v1.5'])\n",
    "ax[0].set_ylabel('Score')\n",
    "\n",
    "evaluated[['recall_negative', 'recall_neutral', 'recall_positive']].plot(kind='bar', ax=ax[1])\n",
    "ax[1].set_title('Recall')\n",
    "ax[1].set_xticklabels(['seBERT', 'SentiStrength-SE_v1.5'])\n",
    "ax[1].set_ylabel('Score')\n",
    "\n",
    "evaluated[['f1_negative', 'f1_neutral', 'f1_positive']].plot(kind='bar', ax=ax[2])\n",
    "ax[2].set_title('F1 Score')\n",
    "ax[2].set_xticklabels(['seBERT', 'SentiStrength-SE_v1.5'])\n",
    "ax[2].set_ylabel('Score')\n",
    "\n",
    "plt.show()"
   ],
   "id": "5f8fda11878b826",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "8d40aa1efdb82629",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
