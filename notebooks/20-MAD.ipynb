{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:09:12.813218Z",
     "start_time": "2024-05-13T23:09:10.784384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import preprocess_text, labelnum\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import timedelta, datetime, timezone\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ],
   "id": "52f7be17dc6448de",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:09:13.579609Z",
     "start_time": "2024-05-13T23:09:13.577430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_PATH = Path('./data/20-MAD/')\n",
    "OUTPUT_PATH = Path('./data/processed/20-MAD/')\n",
    "\n",
    "MODEL_PATH = Path('./models/sentiment/')  "
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:09:15.628297Z",
     "start_time": "2024-05-13T23:09:15.025561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "get_sentiment = pipeline('sentiment-analysis',\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_length=512,\n",
    "                    batch_size=32,\n",
    "                    truncation=True,\n",
    "                    device=device\n",
    "                    )\n",
    "\n",
    "label_map = {'LABEL_0': 'negative',\n",
    "             'LABEL_1': 'neutral',\n",
    "             'LABEL_2': 'positive'}"
   ],
   "id": "331657a6ec0b7afc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Commits",
   "id": "8ef5c9747753bcd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:09:16.622678Z",
     "start_time": "2024-05-13T23:09:16.620456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "commits_path = DATA_PATH / \"commits.parquet\"\n",
    "commits_out_path = OUTPUT_PATH / \"commits.csv\""
   ],
   "id": "3c9144b38481e1cb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:37:41.056195Z",
     "start_time": "2024-05-13T23:37:41.044677Z"
    }
   },
   "cell_type": "code",
   "source": "data = pq.ParquetFile(commits_path)",
   "id": "2ca968a784cc4424",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:37:43.645659Z",
     "start_time": "2024-05-13T23:37:43.641402Z"
    }
   },
   "cell_type": "code",
   "source": "data.metadata",
   "id": "42f86c36cc5e3640",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7e5c2c772250>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 16\n",
       "  num_rows: 3439001\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 3729"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:37:44.248488Z",
     "start_time": "2024-05-13T23:37:44.245123Z"
    }
   },
   "cell_type": "code",
   "source": "data.schema.names",
   "id": "7e32fee358c07c04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source',\n",
       " 'repo',\n",
       " 'hash',\n",
       " 'parents',\n",
       " 'author',\n",
       " 'author_time',\n",
       " 'author_tz',\n",
       " 'committer',\n",
       " 'commit_time',\n",
       " 'commit_tz',\n",
       " 'message',\n",
       " 'added',\n",
       " 'removed',\n",
       " 'from_svn',\n",
       " 'accurate_tz',\n",
       " 'issue_id']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:37:50.048609Z",
     "start_time": "2024-05-13T23:37:50.045253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_column = 'message'\n",
    "non_nullable_columns = [text_column, 'committer', 'repo']\n",
    "chunk_size = 4096"
   ],
   "id": "356d7b2f67b7c42c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T23:37:50.651697Z",
     "start_time": "2024-05-13T23:37:50.649546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if commits_out_path.exists():\n",
    "    commits_out_path.unlink()"
   ],
   "id": "e31c6c3861ccaa5e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-13T23:38:03.987985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = 0\n",
    "for chunk in data.iter_batches(batch_size=chunk_size):\n",
    "    chunk: pd.DataFrame = chunk.to_pandas()\n",
    "    chunk = chunk.dropna(subset=[text_column])\n",
    "    chunk[text_column] = chunk[text_column].apply(preprocess_text)\n",
    "    \n",
    "    sentiments = get_sentiment(chunk[text_column].tolist())\n",
    "    sentiment_labels = [label_map[sentiment['label']] for sentiment in sentiments]\n",
    "    chunk[f'{text_column}_sentiment'] = sentiment_labels\n",
    "    \n",
    "    commit_times = pd.to_datetime(chunk[\"commit_time\"], utc=True)\n",
    "    author_times = pd.to_datetime(chunk[\"author_time\"], utc=True)\n",
    "\n",
    "    commit_tz_values = chunk[\"commit_tz\"]\n",
    "    author_tz_values = chunk[\"author_tz\"]\n",
    "    \n",
    "    chunk[\"local_commit_time\"] = commit_times + pd.to_timedelta(chunk[\"commit_tz\"].apply(lambda x: timedelta(hours=float(x)/100)), unit='h')\n",
    "    chunk[\"local_author_time\"] = author_times + pd.to_timedelta(chunk[\"author_tz\"].apply(lambda x: timedelta(hours=float(x)/100)), unit='h')\n",
    "\n",
    "    chunk[\"part_of_day_commit\"] = pd.cut(chunk[\"local_commit_time\"].dt.hour, bins=[0, 6, 12, 18, 23, 24], labels=[\"Night\", \"Morning\", \"Afternoon\", \"Evening\", \"Night\"], right=False,ordered=False)\n",
    "    chunk[\"part_of_day_author\"] = pd.cut(chunk[\"local_author_time\"].dt.hour, bins=[0, 6, 12, 18, 23, 24], labels=[\"Night\", \"Morning\", \"Afternoon\", \"Evening\", \"Night\"], right=False,ordered=False)\n",
    "    \n",
    "    if commits_out_path.exists():\n",
    "        chunk.to_csv(commits_out_path, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        chunk.to_csv(commits_out_path, mode='w', index=False, header=True)\n",
    "        \n",
    "    count += chunk.shape[0]\n",
    "    print(f\"processed {count} commits\")"
   ],
   "id": "bfc69b8208727e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "90e40ae23b9aff18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ff0f7f45af8ba343"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
